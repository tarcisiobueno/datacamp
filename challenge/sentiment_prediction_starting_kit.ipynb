{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "This notebook provides a baseline model using PU learning techniques to tackle this challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (55913, 3)\n",
      "Test dataset shape: (6347, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"QT @user In the original draft of the 7th boo...</td>\n",
       "      <td>human</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user Alciato: Bee will invest 150 million in ...</td>\n",
       "      <td>human</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user LIT MY MUM 'Kerry the louboutins I wonde...</td>\n",
       "      <td>human</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\\"\"\"\" SOUL TRAIN\\\"\"\"\" OCT 27 HALLOWEEN SPECIA...</td>\n",
       "      <td>human</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So disappointed in wwe summerslam! I want to s...</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       type      label\n",
       "0  \"QT @user In the original draft of the 7th boo...      human          2\n",
       "1  @user Alciato: Bee will invest 150 million in ...      human          2\n",
       "2  @user LIT MY MUM 'Kerry the louboutins I wonde...      human          2\n",
       "3  \"\\\"\"\"\" SOUL TRAIN\\\"\"\"\" OCT 27 HALLOWEEN SPECIA...      human          2\n",
       "4  So disappointed in wwe summerslam! I want to s...  unlabeled  unlabeled"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Display dataset information\n",
    "print(\"Train dataset shape:\", train_df.shape)\n",
    "print(\"Test dataset shape:\", test_df.shape)\n",
    "\n",
    "# Sample of train dataset\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Labels,\n",
    "    \"Before training the model, let's inspect the unique values and their counts in the `label` column for both the training and test datasets.\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in train dataset:\n",
      "['2' 'unlabeled' '0']\n",
      "Label distribution in train dataset:\n",
      "label\n",
      "unlabeled    33059\n",
      "2            21680\n",
      "0             1174\n",
      "Name: count, dtype: int64\n",
      "Unique labels in test dataset:\n",
      "[2 0]\n",
      "Label distribution in test dataset:\n",
      "label\n",
      "0    3972\n",
      "2    2375\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Unique labels and counts in the training dataset\n",
    "print(\"Unique labels in train dataset:\")\n",
    "print(train_df['label'].unique())\n",
    "print(\"Label distribution in train dataset:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "# Unique labels and counts in the test dataset\n",
    "print(\"Unique labels in test dataset:\")\n",
    "print(test_df['label'].unique())\n",
    "print(\"Label distribution in test dataset:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "We will implement a simple **Positive-Unlabeled (PU) learning** model using logistic regression. Since we lack explicit negative labels, we will use a two-step approach:\n",
    "1. Train a naive model using only positive and unlabeled data.\n",
    "2. Use heuristics or additional methods to infer probable negative instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.510138113429327\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Convert text data into numerical features\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_df['text'].astype(str))\n",
    "X_test = vectorizer.transform(test_df['text'].astype(str))\n",
    "\n",
    "# For training data, compare labels as strings\n",
    "y_train = np.where(train_df['label'].astype(str) == '2', 1, 0)  # Positive = 1, Unlabeled = 0\n",
    "\n",
    "# For test data, convert labels to binary (assuming 2 is positive and 0 is negative)\n",
    "y_test = np.where(test_df['label'] == 2, 1, 0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model using F1-score\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Next Steps\n",
    "Participants are encouraged to:\n",
    "- Experiment with different **PU learning techniques** such as **weighted loss functions** or **semi-supervised learning**.\n",
    "- Use **self-training** or **EM algorithms** to improve pseudo-labeling.\n",
    "- Incorporate **pre-trained embeddings (e.g., BERT, RoBERTa)** for feature extraction.\n",
    "\n",
    "Good luck with the challenge!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
