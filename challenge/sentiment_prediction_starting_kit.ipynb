{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "This notebook provides a baseline model using PU learning techniques to tackle this challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (44730, 3)\n",
      "Test dataset shape: (11183, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31309</th>\n",
       "      <td>“my son holds a lot of resentment towards me a...</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30919</th>\n",
       "      <td>i gotta friend who is known for talkin shit al...</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37807</th>\n",
       "      <td>If that's what a voter believe, that explained...</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21499</th>\n",
       "      <td>Snoop Dogg didn't start saying -izzle but he w...</td>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47441</th>\n",
       "      <td>These alternatives to popular apps can help re...</td>\n",
       "      <td>unlabeled</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text       type  label\n",
       "31309  “my son holds a lot of resentment towards me a...  unlabeled      0\n",
       "30919  i gotta friend who is known for talkin shit al...  unlabeled      0\n",
       "37807  If that's what a voter believe, that explained...  unlabeled      0\n",
       "21499  Snoop Dogg didn't start saying -izzle but he w...      human      1\n",
       "47441  These alternatives to popular apps can help re...  unlabeled      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import problem\n",
    "\n",
    "X_df, y = problem.get_train_data()\n",
    "train_df, test_df, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=42)\n",
    "train_df['label'] = y_train\n",
    "test_df['label'] = y_test\n",
    "# Display dataset information\n",
    "print(\"Train dataset shape:\", train_df.shape)\n",
    "print(\"Test dataset shape:\", test_df.shape)\n",
    "\n",
    "# Sample of train dataset\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unlabeled', 'human', 'llm'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at an interesting column in our  dataset : 'type'. This column is referring to the labelling method employed, it takes three values : \n",
    "\n",
    "* 'unlabeled': Which means the text has not been labeled\n",
    "* 'human': Which indicates that the text has been annotated by a human labeler\n",
    "* 'llm': Which indicates the annotation by a LLM (Notably Llama 3.2 2B)\n",
    "\n",
    "Note that the label for unlabeled samples is by default zero. The PU learning task will require you to adjust this label as close as possible to its true value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Labels,\n",
    "    \"Before training the model, let's inspect the unique values and their counts in the `label` column for both the training and test datasets.\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in train dataset:\n",
      "[0 1]\n",
      "Label distribution in train dataset:\n",
      "label\n",
      "0    27365\n",
      "1    17365\n",
      "Name: count, dtype: int64\n",
      "Unique labels in test dataset:\n",
      "[0 1]\n",
      "Label distribution in test dataset:\n",
      "label\n",
      "0    6868\n",
      "1    4315\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Unique labels and counts in the training dataset\n",
    "print(\"Unique labels in train dataset:\")\n",
    "print(train_df['label'].unique())\n",
    "print(\"Label distribution in train dataset:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "# Unique labels and counts in the test dataset\n",
    "print(\"Unique labels in test dataset:\")\n",
    "print(test_df['label'].unique())\n",
    "print(\"Label distribution in test dataset:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "We will implement a simple **Positive-Unlabeled (PU) learning** model using logistic regression. Since we lack explicit negative labels, we will use a two-step approach:\n",
    "1. Train a naive model using only positive and unlabeled data.\n",
    "2. Use heuristics or additional methods to infer probable negative instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.7233883989566513\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Convert text data into numerical features\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_df['text'].astype(str))\n",
    "X_test = vectorizer.transform(test_df['text'].astype(str))\n",
    "\n",
    "# For training data, compare labels as strings\n",
    "y_train = train_df['label']\n",
    "\n",
    "# For test data, convert labels to binary (assuming 2 is positive and 0 is negative)\n",
    "y_test = test_df['label']\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model using F1-score\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this score is artificially inflated as the labels for 'unlabeled' test is incorrectly set to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining it in a sklearn pipeline and evaluating the score with cross-validation gives the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "def get_tf_idf_features(X_df):\n",
    "    tf_idf = TfidfVectorizer(max_features=100)\n",
    "    X_df_features = tf_idf.fit_transform(X_df['text'].astype(str))\n",
    "    return X_df_features.toarray() # Convert to dense format \n",
    "\n",
    "cols = ['text']\n",
    "\n",
    "transformer = make_column_transformer(\n",
    "    (FunctionTransformer(lambda X_df: get_tf_idf_features(X_df)), cols),\n",
    ")\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    transformer,\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "def get_estimator():\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54706341 0.31926659]\n"
     ]
    }
   ],
   "source": [
    "import problem\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_df, y = problem.get_train_data()\n",
    "\n",
    "scores = cross_val_score(get_estimator(), X_df, y, cv=2, scoring='f1')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Next Steps\n",
    "Participants are encouraged to:\n",
    "- Experiment with different **PU learning techniques** such as **weighted loss functions** or **semi-supervised learning**.\n",
    "- Use **self-training** or **EM algorithms** to improve pseudo-labeling.\n",
    "- Incorporate **pre-trained embeddings (e.g., BERT, RoBERTa)** for feature extraction.\n",
    "\n",
    "Good luck with the challenge!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
